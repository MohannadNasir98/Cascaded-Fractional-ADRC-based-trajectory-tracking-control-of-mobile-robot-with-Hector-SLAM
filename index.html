<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Cascaded Fractional ADRC with Hector SLAM</title>
  <style>
    body {
      font-family: Arial, sans-serif;
      margin: 0;
      padding: 0;
      background-color: #f4f4f4;
      color: #333;
    }
    /* Top project info bar (was footer) */
    .top-banner {
      background-color: #2c3e50;
      color: #fff;
      padding: 10px;
      text-align: center;
      font-size: 0.95em;
    }
    header {
      background-color: #2c3e50;
      color: #fff;
      padding: 20px;
      text-align: center;
    }
    section {
      padding: 20px;
      margin: 10px auto;
      max-width: 900px;
      background-color: #fff;
      border-radius: 8px;
      box-shadow: 0 2px 4px rgba(0,0,0,0.1);
    }
    h2 {
      color: #2c3e50;
    }
    footer {
      text-align: center;
      padding: 10px;
      background-color: #2c3e50;
      color: white;
      margin-top: 30px;
    }
    img {
      max-width: 100%;
      display: block;
      margin: 10px 0;
    }
  </style>
</head>
<body>

  <!-- Moved project info banner to top -->
  <div class="top-banner">
    Project by Mohannad Nasir | Course: Robotic Perception | Professor: Jorge Dias | Khalifa University | May 2025
  </div>

  <header>
    <h1>Cascaded Fractional ADRC-Based Trajectory Tracking Control of Mobile Robot with Hector SLAM</h1>
  </header>


  <section id="abstract">
    <h2>Abstract</h2>
    <p>
      This research presents the design, implementation, and simulation of a robust trajectory tracking control system for a mobile robot by integrating Hector SLAM with a fractional Cascaded Active Disturbance Rejection Control (FADRC) strategy. The system is designed to operate solely with a 2D LiDAR sensor for real-time environmental perception and navigation, avoiding the need for wheel encoders or inertial sensors.
    </p>
    <p>
      This proposed approach is motivated by the limitations of conventional control methods such as PID and conventional ADRC, which often struggle in dealing with real world challenges such as measurement noise, unmodeled dynamics, and external disturbances in real-world environments. By using Hector SLAM, the system can achieve accurate localization from laser scans alone, while FADRC can improve control robustness by compensating for external disturbances, and dealing with real world challenges through a fractional-order and multi-layered observer structure.
    </p>
    <p>
      The FADRC control architecture combines a fractional-order Extended State Observer (ESO) with a cascaded loop to enhance disturbance estimation and rejection. The system is evaluated through simulation across various trajectories—including circular, infinity, and scenarios with sudden disturbances—and benchmarked against a classical PID controller to highlight performance gains in tracking accuracy and responsiveness.
    </p>
    <p>
      The results demonstrate that the proposed Hector SLAM and FADRC integration enables reliable and precise trajectory tracking under noisy and dynamic conditions. This contributes to the development of more robust, sensor-efficient autonomous robots, offering a practical solution for environments where odometry is unreliable or unavailable, with broader implications for advancing intelligent and adaptable robotic systems.
    </p>
  </section>

  <section id="methodology">
    <h2>1. Methodology</h2>
    <p>
      The overall methodology consists of two primary modules: localization using Hector SLAM and robust control using FADRC. The figure below presents the integrated framework of the system.
    </p>
  <img src="https://raw.githubusercontent.com/MohannadNasir98/Cascaded-Fractional-ADRC-based-trajectory-tracking-control-of-mobile-robot-with-Hector-SLAM/main/System%20Archt_v2.png">
    <p>
      In the Figure, the desired trajectory is fed into a finite difference module to compute the required velocity commands. These are compared with real velocity estimates, calculated from the real position obtained via Hector SLAM using LiDAR scans. The error between desired and real velocities is processed by a PD controller, which generates a nominal control input. This is augmented by disturbance estimates provided by a set of Fractional-order Extended State Observers (FESOs), operating in a cascaded way to capture unmodeled dynamics and external disturbances. The final control signal is then scaled by an estimated control gain inverse and applied to the robot model.
    </p>
    <p>
      The localization system, powered by Hector SLAM, continuously updates the robot’s real-time position using only the LiDAR data, ensuring odometry-free operation. The control loop relies on accurate pose feedback to close the loop and update the velocity tracking error, forming a complete SLAM-control integration.
      To support the simulation and real-time implementation of the proposed methodology, a modular ROS-based architecture was developed, as shown in Figure 2. The system leverages Gazebo for simulating the TurtleBot3 robot and environment. The robot model continuously publishes laser scan data, which is consumed by the Hector SLAM node to estimate the robot’s current pose. The estimated pose is then passed to the FCADRC controller node, which computes control commands based on a predefined trajectory and real-time feedback. These commands are published to the /cmd_vel topic, closing the control loop. Logging mechanisms are also included for performance analysis and validation, comparing the actual and reference trajectories.
    <p>
  <img src="https://raw.githubusercontent.com/MohannadNasir98/Cascaded-Fractional-ADRC-based-trajectory-tracking-control-of-mobile-robot-with-Hector-SLAM/main/System%20Interface_V2.png">
    </p>
    </p>
  </section>

  <section id="system-architecture">
    <h2>2. System Architecture</h2>
    <p>The overall architecture consists of:</p>
    <ul>
      <li><strong>LiDAR Perception:</strong> 2D RPLiDAR for environment mapping</li>
      <li><strong>Hector SLAM:</strong> Provides real-time pose estimation from laser scans</li>
      <li><strong>Controller:</strong> Cascaded Fractional ADRC with n-Extended State Observers</li>
      <li><strong>Mobile Base:</strong> Differential Drive Mobile Robot simulated in Gazebo world (Turtlebot3)</li>
    </ul>
  </section>

  <section id="results">
  <h2>4. Results and Discussion</h2>
  <p>
    A comprehensive set of simulation scenarios was conducted to evaluate the robustness, tracking accuracy, and generalizability of the proposed Fractional Cascaded Active Disturbance Rejection Control (FCADRC) system, in comparison to classical PID and conventional ADRC controllers. Four test cases were explored:
  </p>
  <ul>
    <li><strong>Case 1:</strong> Circular trajectory tracking under ideal, noise-free, and disturbance-free conditions.</li>
    <li><strong>Case 2:</strong> Same circular trajectory with added Gaussian sensor noise (standard deviation = 0.01).</li>
    <li><strong>Case 3:</strong> Circular trajectory tracking with step disturbances applied at 6–8s (0.3 m/s linear, 0.2 rad/s angular).</li>
    <li><strong>Case 4:</strong> A complex infinity-shaped trajectory under both noise and step disturbances (10–12s).</li>
  </ul>

  <p>
    Under ideal conditions (Case 1), the FCADRC demonstrated superior performance with minimal overshoot, fastest convergence, and the most precise velocity tracking. When Gaussian noise was introduced (Case 2), its multi-layered disturbance estimation architecture proved resilient, maintaining stable control where PID noticeably degraded. In Case 3, the FCADRC rapidly compensated for abrupt disturbances, significantly outperforming both PID and ADRC in disturbance rejection and recovery time. Case 4, designed as the most demanding scenario, validated the controller’s robustness under both dynamic trajectory and external disturbances, with FCADRC showing minimal deviation and consistent tracking despite increased system complexity.
  </p>

  <p>
    The effectiveness of each controller was also quantified using the Mean Squared Error (MSE) for both linear and angular velocities, across all scenarios:
  </p>

  <table>
    <caption><strong>Table 1:</strong> MSE comparison between PID, ADRC, and FCADRC for linear and angular velocities across all cases</caption>
    <thead>
      <tr>
        <th>Test Case</th>
        <th>Velocity</th>
        <th>PID</th>
        <th>ADRC</th>
        <th>FCADRC</th>
      </tr>
    </thead>
    <tbody>
      <tr><td rowspan="2">Case 1</td><td>Linear (v)</td><td>0.0045</td><td>0.0030</td><td>0.0015</td></tr>
      <tr><td>Angular (ω)</td><td>0.0467</td><td>0.0239</td><td>0.0190</td></tr>

      <tr><td rowspan="2">Case 2</td><td>Linear (v)</td><td>0.0048</td><td>0.0030</td><td>0.0015</td></tr>
      <tr><td>Angular (ω)</td><td>0.0579</td><td>0.0272</td><td>0.0190</td></tr>

      <tr><td rowspan="2">Case 3</td><td>Linear (v)</td><td>0.0047</td><td>0.0032</td><td>0.0025</td></tr>
      <tr><td>Angular (ω)</td><td>0.0475</td><td>0.0248</td><td>0.0235</td></tr>

      <tr><td rowspan="2">Case 4</td><td>Linear (v)</td><td>0.0014</td><td>0.0013</td><td>0.0005</td></tr>
      <tr><td>Angular (ω)</td><td>0.0260</td><td>0.0257</td><td>0.0147</td></tr>
    </tbody>
  </table>

  <p>
    As shown in Table 1, the FCADRC consistently yields the lowest MSE values across all test scenarios, demonstrating its enhanced tracking precision and robustness to both noise and disturbances. Notably, its performance advantage becomes more pronounced in the presence of uncertainties, where PID and even ADRC exhibit higher errors and delayed recovery.
  </p>

  <p>
    To further validate generalizability, the same controller and tuned parameters were applied without modification to a second mobile robot, the Pioneer 3-DX (P3DX), which differs in physical characteristics and dynamic parameters (especially in its input gain matrix). Even under the most complex condition—an infinity trajectory with disturbances and noise—the FCADRC maintained stable, accurate tracking behavior. This confirms the controller’s platform-independence and minimal need for retuning, highlighting its suitability for real-world deployment across different robotic platforms.
  </p>

<section id="demo">
  <h2>5. Demonstration Video</h2>
  <p>
    To provide a clearer understanding of the controller's real-time behavior and practical effectiveness, the following demo video showcases the FCADRC-based trajectory tracking performance under the most complex test scenario (Case 4), which involves an infinity-shaped path, Gaussian sensor noise, and step disturbances.
  </p>

  <div style="text-align: center; margin-top: 15px;">
    <iframe src="https://drive.google.com/file/d/1YDquf4-z0W8uTb8dfqrh8lrPM-xDl1gl/preview"
            width="720" height="405" allow="autoplay" allowfullscreen></iframe>
  </div>
</section>

<section id="conclusion">
  <h2>6. Conclusion and Future Work</h2>
  <p>
    This research presented the design and simulation of a robust trajectory tracking controller using FCADRC integrated with Hector SLAM for localization.
    The system was tested on the TurtleBot3 in a ROS-Gazebo environment using only a 2D LiDAR. Across four test cases, FCADRC consistently outperformed classical PID and standard ADRC in tracking accuracy, disturbance rejection, and noise robustness.
    To assess generalizability, the same controller was applied to a second robot, the P3DX, with different dynamics and a distinct <i>b<sub>0</sub></i> value.
    The FCADRC maintained high performance without re-tuning, confirming its adaptability across platforms and strong potential for real-world deployment.
  </p>

  <p>
    For future work, the simulation can be extended to real-time hardware implementation. A practical prototype may include a Raspberry Pi 4B for SLAM and control,
    an RPLiDAR A1 sensor for localization, and an Arduino Uno with an L293D motor driver for actuator control, as illustrated in the below Figure.
    Wireless communication via a Wi-Fi router would allow remote monitoring. This setup enables validation of FCADRC under real-world constraints
    such as sensor noise and communication delays. Further research may also explore its scalability to more complex robots and its application to
    multi-robot coordination or autonomous navigation in unknown environments.
  </p>

  <div style="text-align: center; margin-top: 20px;">
    <img src="Future hardware implementation_v2.png" alt="Hardware Implementation Diagram" width="600" />
  </div>
</section>



    
</body>
</html>
