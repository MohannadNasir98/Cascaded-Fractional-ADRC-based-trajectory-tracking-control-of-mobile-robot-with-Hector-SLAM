<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Cascaded Fractional ADRC with Hector SLAM</title>
  <style>
    body {
      font-family: Arial, sans-serif;
      margin: 0;
      padding: 0;
      background-color: #f4f4f4;
      color: #333;
    }
    header {
      background-color: #2c3e50;
      color: #fff;
      padding: 20px;
      text-align: center;
    }
    section {
      padding: 20px;
      margin: 10px auto;
      max-width: 900px;
      background-color: #fff;
      border-radius: 8px;
      box-shadow: 0 2px 4px rgba(0,0,0,0.1);
    }
    h2 {
      color: #2c3e50;
    }
    footer {
      text-align: center;
      padding: 10px;
      background-color: #2c3e50;
      color: white;
      margin-top: 30px;
    }
    img {
      max-width: 100%;
      display: block;
      margin: 10px 0;
    }
  </style>
</head>
<body>
  <header>
    <h1>Cascaded Fractional ADRC-Based Trajectory Tracking Control of Mobile Robot with Hector SLAM</h1>
    <p>First Version - Project Webpage</p>
  </header>

  <section id="abstract">
    <h2>Abstract</h2>
    <p>
      This research presents the design, implementation, and simulation of a robust trajectory tracking control system for a mobile robot by integrating Hector SLAM with a fractional Cascaded Active Disturbance Rejection Control (FADRC) strategy. The system is designed to operate solely with a 2D LiDAR sensor for real-time environmental perception and navigation, avoiding the need for wheel encoders or inertial sensors.
    </p>
    <p>
      This proposed approach is motivated by the limitations of conventional control methods such as PID and conventional ADRC, which often struggle in dealing with real world challenges such as measurement noise, unmodeled dynamics, and external disturbances in real-world environments. By using Hector SLAM, the system can achieve accurate localization from laser scans alone, while FADRC can improve control robustness by compensating for external disturbances, and dealing with real world challenges through a fractional-order and multi-layered observer structure.
    </p>
    <p>
      The FADRC control architecture combines a fractional-order Extended State Observer (ESO) with a cascaded loop to enhance disturbance estimation and rejection. The system is evaluated through simulation across various trajectories—including circular, infinity, and scenarios with sudden disturbances—and benchmarked against a classical PID controller to highlight performance gains in tracking accuracy and responsiveness.
    </p>
    <p>
      The results demonstrate that the proposed Hector SLAM and FADRC integration enables reliable and precise trajectory tracking under noisy and dynamic conditions. This contributes to the development of more robust, sensor-efficient autonomous robots, offering a practical solution for environments where odometry is unreliable or unavailable, with broader implications for advancing intelligent and adaptable robotic systems.
    </p>
  </section>

  <section id="methodology">
    <h2>1. Methodology</h2>
    <p>
      The overall methodology consists of two primary modules: localization using Hector SLAM and robust control using FADRC. The figure below presents the integrated framework of the system.
    </p>
  <img src="https://raw.githubusercontent.com/MohannadNasir98/Cascaded-Fractional-ADRC-based-trajectory-tracking-control-of-mobile-robot-with-Hector-SLAM/main/Overall%20Sys%20Archt%20V1.png">
    <p>
      In the Figure, the desired trajectory is fed into a finite difference module to compute the required velocity commands. These are compared with real velocity estimates, calculated from the real position obtained via Hector SLAM using LiDAR scans. The error between desired and real velocities is processed by a PD controller, which generates a nominal control input. This is augmented by disturbance estimates provided by a set of Fractional-order Extended State Observers (FESOs), operating in a cascaded way to capture unmodeled dynamics and external disturbances. The final control signal is then scaled by an estimated control gain inverse and applied to the robot model.
    </p>
    <p>
      The localization system, powered by Hector SLAM, continuously updates the robot’s real-time position using only the LiDAR data, ensuring odometry-free operation. The control loop relies on accurate pose feedback to close the loop and update the velocity tracking error, forming a complete SLAM-control integration.
    </p>
  </section>

  <section id="system-architecture">
    <h2>2. System Architecture</h2>
    <p>The overall architecture consists of:</p>
    <ul>
      <li><strong>LiDAR Perception:</strong> 2D RPLiDAR for environment mapping</li>
      <li><strong>Hector SLAM:</strong> Provides real-time pose estimation from laser scans</li>
      <li><strong>Controller:</strong> Cascaded Fractional ADRC with n-Extended State Observers</li>
      <li><strong>Mobile Base:</strong> Differential Drive Mobile Robot simulated in Gazebo world (Turtlebot3)</li>
    </ul>
    <p>A block diagram and node graph visualization will be added soon.</p>
  </section>

  <section id="simulation-scenarios">
    <h2>3. Simulation Scenarios</h2>
    <p>Multiple control cases were designed and executed to validate system performance against PID controller:</p>
    <ul>
      <li>Circular trajectory tracking under normal conditions</li>
      <li>Circular trajectory with moderate noise in feedback</li>
      <li>Sudden external disturbances with the same trajectory</li>
      <li>Complex trajectory (e.g., infinity path) with both noisy measurements and sudden external disturbance</li>
    </ul>
    <p>Each scenario demonstrates robustness, tracking accuracy, and response sharpness of the proposed FADRC method.</p>
  </section>

  <section id="results">
    <h2>4. Results (Coming Soon)</h2>
    <p>Simulation plots and videos for the above test cases will be included in the next version:</p>
    <ul>
      <li>Trajectory tracking plots (x, y)</li>
      <li>Control signals (v, w) and estimated disturbances</li>
      <li>Comparison graphs (FADRC vs PID)</li>
      <li>Demo videos embedded or linked</li>
    </ul>
  </section>

  <footer>
    <p>Project by Mohannad Nasir | Course: Robotic Perception | Professor: Jorge Dias | Khalifa University | 2025</p>
  </footer>
</body>
</html>
